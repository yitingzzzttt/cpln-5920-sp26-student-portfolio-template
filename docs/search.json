[
  {
    "objectID": "Labs/Lab_1/lab1_template.html",
    "href": "Labs/Lab_1/lab1_template.html",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the CA Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/labs/lab_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Labs” menu."
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#scenario",
    "href": "Labs/Lab_1/lab1_template.html#scenario",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the CA Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#learning-objectives",
    "href": "Labs/Lab_1/lab1_template.html#learning-objectives",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#submission-instructions",
    "href": "Labs/Lab_1/lab1_template.html#submission-instructions",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/labs/lab_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Labs” menu."
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#data-retrieval",
    "href": "Labs/Lab_1/lab1_template.html#data-retrieval",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\ncounty_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    med_income = \"B19013_001\",\n    total_pop = \"B01003_001\"\n  ),\n  state = my_state,\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n)\n\n# Clean the county names to remove state name and \"County\" \n\n# Hint: use mutate() with str_remove()\ncounty_data_clean &lt;- county_data %&gt;%\n  mutate(NAME = str_remove(NAME, \"County, California\"))\n\n# Display the first few rows\nhead(county_data_clean)\n\n# A tibble: 6 × 6\n  GEOID NAME         med_incomeE med_incomeM total_popE total_popM\n  &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 06001 \"Alameda \"        122488        1231    1663823         NA\n2 06003 \"Alpine \"         101125       17442       1515        206\n3 06005 \"Amador \"          74853        6048      40577         NA\n4 06007 \"Butte \"           66085        2261     213605         NA\n5 06009 \"Calaveras \"       77526        3875      45674         NA\n6 06011 \"Colusa \"          69619        5745      21811         NA"
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#data-quality-assessment",
    "href": "Labs/Lab_1/lab1_template.html#data-quality-assessment",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\n# Calculate MOE percentage and reliability categories using mutate()\nincome_analysis &lt;- county_data_clean %&gt;%\n  mutate(\n    moe_pct = (med_incomeM / med_incomeE) * 100,\n    reliability = case_when(\n      moe_pct &lt; 5 ~ \"High Confidence\",\n      moe_pct &lt;= 10 ~ \"Moderate Confidence\",\n      TRUE ~ \"Low Confidence\"\n    ),\n    unreliable_flag = if_else(moe_pct &gt; 10, \"Yes\", \"No\")\n  )\n\n# Create a summary showing count of counties in each reliability category\nreliability_summary &lt;- income_analysis %&gt;%\n  count(reliability) %&gt;%\n  mutate(\n    percentage = (n / sum(n)) * 100\n  )\n\nkable(reliability_summary, digits = 1, caption = \"Summary of Data Reliability by County\")\n\n\nSummary of Data Reliability by County\n\n\nreliability\nn\npercentage\n\n\n\n\nHigh Confidence\n42\n72.4\n\n\nLow Confidence\n5\n8.6\n\n\nModerate Confidence\n11\n19.0\n\n\n\n\n# Hint: use count() and mutate() to add percentages"
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#high-uncertainty-counties",
    "href": "Labs/Lab_1/lab1_template.html#high-uncertainty-counties",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\n# Create table of top 5 counties by MOE percentage\nhigh_uncertainty_top5 &lt;- income_analysis %&gt;%\n  arrange(desc(moe_pct))%&gt;%\n  slice(1:5)%&gt;%\n  select(\n    NAME,\n    med_incomeE,\n    med_incomeM,\n    moe_pct,\n    reliability\n  )\n\n# Format as table with kable() - include appropriate column names and caption\nkable(\nhigh_uncertainty_top5, \n      col.names = c(\"County Name\", \"Median Income (Estimate)\", \"Margin of Error\", \"MOE %\", \"Reliability\"),\ndigits = 2,\ncaption = \"Top 5 counties with the highest Uncertainty\"\n)\n\n\nTop 5 counties with the highest Uncertainty\n\n\n\n\n\n\n\n\n\nCounty Name\nMedian Income (Estimate)\nMargin of Error\nMOE %\nReliability\n\n\n\n\nMono\n82038\n15388\n18.76\nLow Confidence\n\n\nAlpine\n101125\n17442\n17.25\nLow Confidence\n\n\nSierra\n61108\n9237\n15.12\nLow Confidence\n\n\nTrinity\n47317\n5890\n12.45\nLow Confidence\n\n\nPlumas\n67885\n7772\n11.45\nLow Confidence\n\n\n\n\n\nData Quality Commentary:\n[Write 2-3 sentences explaining what these results mean for algorithmic decision-making. Consider: Which counties might be poorly served by algorithms that rely on this income data? What factors might contribute to higher uncertainty?]\n“The high MOE percentages in rural counties like Mono and Alpine (both over 17%) indicate that small sample sizes in sparsely populated areas lead to significant data instability. If algorithmic systems treat these”Low Confidence” estimates as absolute facts, they risk misallocating social services and reinforcing geographic inequities against rural communities. Consequently, these communities may be poorly served by automated decisions that fail to account for the inherent statistical uncertainty in their income data.”"
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#focus-area-selection",
    "href": "Labs/Lab_1/lab1_template.html#focus-area-selection",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n# Use filter() to select 2-3 counties from your county_reliability data\n# Store the selected counties in a variable called selected_counties\nselected_counties&lt;- income_analysis%&gt;%\n  group_by(reliability) %&gt;%\n  slice(1) %&gt;%\n  ungroup() %&gt;%\n  select(NAME, GEOID, med_incomeE, moe_pct, reliability)\n\n# Display the selected counties with their key characteristics\nkable(\nselected_counties, \n      col.names = c(\"County Name\", \"GEOID\", \"Median Income (Estimate)\", \"MOE %\", \"Reliability\"),\ndigits = 3,\ncaption = \"Representative Counties Selected for Each Reliability Level\"\n)\n\n\nRepresentative Counties Selected for Each Reliability Level\n\n\n\n\n\n\n\n\n\nCounty Name\nGEOID\nMedian Income (Estimate)\nMOE %\nReliability\n\n\n\n\nAlameda\n06001\n122488\n1.005\nHigh Confidence\n\n\nAlpine\n06003\n101125\n17.248\nLow Confidence\n\n\nAmador\n06005\n74853\n8.080\nModerate Confidence\n\n\n\n\n# Show: county name, median income, MOE percentage, reliability category\n\nComment on the output: [I selected “Alameda”, ““Amador”, and “Alpine” to represent High, Moderate, and Low Confidence levels respectively. ]"
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#tract-level-demographics",
    "href": "Labs/Lab_1/lab1_template.html#tract-level-demographics",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements: - Geography: tract level - Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001) - Use the same state and year as before - Output format: wide - Challenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# Define your race/ethnicity variables with descriptive names\nrace_var &lt;- c(\n  total_pop= \"B03002_001\",\n  white_alone=\"B03002_003\",\n  black=\"B03002_004\",\n  hispanic_latino=\"B03002_012\"\n)\n# Use get_acs() to retrieve tract-level data\ntarget_counties &lt;- str_sub(selected_counties$GEOID, 3, 5)\n\ntract_data&lt;-get_acs(\n  geography = \"tract\",\n  variables = race_var,\n  state = my_state,\n  county = target_counties,\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n  \n)\n# Hint: You may need to specify county codes in the county parameter\n\n# Calculate percentage of each group using mutate()\ntract_demographics &lt;- tract_data %&gt;%\n  mutate(\n    pct_white= (white_aloneE/total_popE)*100,\n    pct_black=(blackE/total_popE)*100,\n    pct_h_l=(hispanic_latinoE/total_popE)*100,\n    county_name = str_extract(NAME, \"(?&lt;=; ).*(?= County;)\"),\n    tract_name = str_extract(NAME, \"^[^,]*\"\n  ))\n# Create percentages for white, Black, and Hispanic populations\n\n# Add readable tract and county name columns using str_extract() or similar"
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#demographic-analysis",
    "href": "Labs/Lab_1/lab1_template.html#demographic-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\n\n# Find the tract with the highest percentage of Hispanic/Latino residents\n# Hint: use arrange() and slice() to get the top tract\nhighest_h_l &lt;- tract_demographics %&gt;%\n  arrange(desc(pct_h_l)) %&gt;%\n  slice(1) %&gt;%\n  select(NAME,pct_h_l, total_popE )\n# Calculate average demographics by county using group_by() and summarize()\naverage_demographics_couty &lt;- tract_demographics %&gt;%\n  group_by(county_name) %&gt;%\n  summarise(\n    tract_count= n(),\n    avg_white=mean(pct_white, na.rm = TRUE),\n    avg_black=mean(pct_black, na.rm = TRUE),\n    avg_h_l=mean( pct_h_l, na.rm = TRUE),\n  )\n# Show: number of tracts, average percentage for each racial/ethnic group\n\n# Create a nicely formatted table of your results using kable()\nkable(\naverage_demographics_couty, \n      col.names = c(\"County\", \"Total Tracts\", \"Avg White %\", \"Avg Black %\", \"Avg Hispanic %\"),\ndigits = 3,\ncaption = \"Demographic Analysis of Selected County\"\n)\n\n\nDemographic Analysis of Selected County\n\n\nCounty\nTotal Tracts\nAvg White %\nAvg Black %\nAvg Hispanic %\n\n\n\n\nAlameda\n379\n31.033\n10.706\n21.385\n\n\nAlpine\n1\n58.086\n0.000\n14.059\n\n\nAmador\n10\n75.665\n1.552\n14.873"
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#moe-analysis-for-demographic-variables",
    "href": "Labs/Lab_1/lab1_template.html#moe-analysis-for-demographic-variables",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\n\n# Calculate MOE percentages for white, Black, and Hispanic variables\n# Hint: use the same formula as before (margin/estimate * 100)\n# Create a flag for tracts with high MOE on any demographic variable\n# Use logical operators (| for OR) in an ifelse() statement\nmoe_analysis &lt;- tract_data %&gt;%\n  mutate(\n  moe_white = ((white_aloneM/white_aloneE)*100),\n  moe_black = ((blackM/blackE)*100),\n  moe_h_l = ((hispanic_latinoM/hispanic_latinoE)*100),\n  moe_total_pop=((total_popM/total_popE)*100),\n  high_moe_flag = if_else(\n  (is.infinite(moe_white)& moe_white &gt;15)|\n  (is.infinite(moe_black)& moe_black &gt;15)|\n  (is.infinite(moe_h_l)& moe_h_l &gt;15),\n  \"High Uncertainty\",\"Reliable\"\n))\n\n# Create summary statistics showing how many tracts have data quality issues\nmoe_sum&lt;- moe_analysis %&gt;%\n  count(high_moe_flag) %&gt;%\n  mutate(pct =(n/sum(n))*100)\n\nkable(moe_sum, caption = \"Summary of Tract-Level Data Quality Issues\")\n\n\nSummary of Tract-Level Data Quality Issues\n\n\nhigh_moe_flag\nn\npct\n\n\n\n\nHigh Uncertainty\n14\n3.589744\n\n\nReliable\n376\n96.410256"
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#pattern-analysis",
    "href": "Labs/Lab_1/lab1_template.html#pattern-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n# Group tracts by whether they have high MOE issues\n# Calculate average characteristics for each group:\n# - population size, demographic percentages\n# Use group_by() and summarize() to create this comparison\n\npatten_analysis &lt;- moe_analysis %&gt;%\n  mutate(\n    pct_white=((white_aloneE/total_popE)*100),\n    pct_black=((blackE/total_popE)*100),\n    pct_h_l=((hispanic_latinoE/total_popE)*100)\n  )%&gt;%\n  group_by(high_moe_flag)%&gt;%\n  summarise(\n    avg_white=mean(pct_white, na.rm = TRUE),\n    avg_black=mean(pct_black, na.rm = TRUE),\n    avg_h_l=mean(pct_h_l, na.rm = TRUE),\n    avg_total=mean(total_popE, na.rm = TRUE),\n    tract_count=n()\n  )\n# Create a professional table showing the patterns\nkable(patten_analysis,\n      col.names = c(\"Data Quality Group\", \"Avg white %\", \"Avg Black %\", \"Avg Hispanic %\",\"Avg Total Pop\", \"Tract Counts\"),\ndigits = 2,\ncaption = \"Summary of Pattern Analysis\")\n\n\nSummary of Pattern Analysis\n\n\n\n\n\n\n\n\n\n\nData Quality Group\nAvg white %\nAvg Black %\nAvg Hispanic %\nAvg Total Pop\nTract Counts\n\n\n\n\nHigh Uncertainty\n48.83\n0.83\n12.96\n2729.64\n14\n\n\nReliable\n31.72\n10.75\n21.46\n4435.37\n376\n\n\n\n\n\nPattern Analysis: [Describe any patterns you observe. Do certain types of communities have less reliable data? What might explain this?] Tracts with sparse populations exhibit high uncertainty due to limited sample sizes, resulting in imprecise data and a significant margin of error. In analyses, data from white populations in high-uncertainty tracts appear unreliable not because of racial issues, but because residents in sparsely populated rural areas tend to be more ethnically homogeneous than those in diverse urban centers. Consequently, higher average proportions of white residents are observed within the “high uncertainty” group."
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#analysis-integration-and-professional-summary",
    "href": "Labs/Lab_1/lab1_template.html#analysis-integration-and-professional-summary",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements: 1. Overall Pattern Identification: What are the systematic patterns across all your analyses? 2. Equity Assessment: Which communities face the greatest risk of algorithmic bias based on your findings? 3. Root Cause Analysis: What underlying factors drive both data quality issues and bias risk? 4. Strategic Recommendations: What should the Department implement to address these systematic issues?\nExecutive Summary:\n[Your integrated 4-paragraph summary here] 1. Across all four levels of analysis, a clear systematic pattern emerges: data reliability is inversely correlated with population density. At the county level, urban centers like Alameda exhibit high confidence with a margin of error (MOE) as low as 1.005%, whereas sparsely populated rural counties like Alpine suffer from low confidence with MOEs exceeding 17.2%. This trend persists at the tract level, where “High Uncertainty” areas have a significantly smaller average population (2,729) compared to “Reliable” tracts (4,435).\n\nThe communities facing the greatest risk of algorithmic bias are small, rural, and geographically isolated populations. Based on the pattern analysis, these “High Uncertainty” tracts often have a higher average percentage of White residents (48.83%) and significantly lower percentages of Black residents (0.83%) compared to urban centers. While urban minority communities benefit from the robust data of high-density areas, rural residents—regardless of race—are at risk of being “miscalculated” by algorithms that do not account for the high statistical noise inherent in small-sample data.\nThe primary driver of this bias risk is the inherent limitation of sampling in low-density areas. In a county like Alpine, which has a total population of only 1,515, the American Community Survey (ACS) sample size is so small that a few outlier responses can drastically skew the median income estimate. Algorithms treat these estimates as absolute facts, but in reality, they are “statistical flukes” caused by the geographic reality of rural life, creating a structural bias where data-rich urban areas receive more predictable and “fair” algorithmic treatment than data-sparse rural ones.\nTo mitigate these risks, the Department of Human Services should implement a “Reliability-Aware” Decision Framework. First, any community flagged with an MOE &gt; 10% should be diverted from fully automated processing to a manual administrative review. Second, the Department should supplement Census data with local administrative records (such as state tax or utility data) for rural tracts to triangulate income estimates."
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#specific-recommendations",
    "href": "Labs/Lab_1/lab1_template.html#specific-recommendations",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\n\n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\n\ndecision_framework &lt;- income_analysis %&gt;%\n  select( NAME, med_incomeE, moe_pct,total_popE,reliability,) %&gt;%\n  mutate(\n    algo_recommendation = case_when(\n      reliability == \"High Confidence\"~\"Safe for algorithmic decisions\",\n      reliability == \"Moderate Confidence\"~\"Use with caution - monitor outcomes\",\n      reliability == \"Low Confidence\"~\"Requires manual review or additional data\"\n  ))\n# Format as a professional table with kable()\nkable(decision_framework,\n      col.names = c(\"county name\", \"median income\", \"MOE percentage\", \"Total population\",\"Reliability\",\"Policy Recommendation\"),\ndigits = 2,\ncaption = \"Decision Framework for Algorithm Implementation\")\n\n\nDecision Framework for Algorithm Implementation\n\n\n\n\n\n\n\n\n\n\ncounty name\nmedian income\nMOE percentage\nTotal population\nReliability\nPolicy Recommendation\n\n\n\n\nAlameda\n122488\n1.00\n1663823\nHigh Confidence\nSafe for algorithmic decisions\n\n\nAlpine\n101125\n17.25\n1515\nLow Confidence\nRequires manual review or additional data\n\n\nAmador\n74853\n8.08\n40577\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nButte\n66085\n3.42\n213605\nHigh Confidence\nSafe for algorithmic decisions\n\n\nCalaveras\n77526\n5.00\n45674\nHigh Confidence\nSafe for algorithmic decisions\n\n\nColusa\n69619\n8.25\n21811\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nContra Costa\n120020\n1.25\n1162648\nHigh Confidence\nSafe for algorithmic decisions\n\n\nDel Norte\n61149\n7.16\n27462\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nEl Dorado\n99246\n3.36\n191713\nHigh Confidence\nSafe for algorithmic decisions\n\n\nFresno\n67756\n1.43\n1008280\nHigh Confidence\nSafe for algorithmic decisions\n\n\nGlenn\n64033\n6.19\n28657\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nHumboldt\n57881\n3.68\n136132\nHigh Confidence\nSafe for algorithmic decisions\n\n\nImperial\n53847\n4.11\n179578\nHigh Confidence\nSafe for algorithmic decisions\n\n\nInyo\n63417\n8.60\n18829\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nKern\n63883\n2.07\n906883\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKings\n68540\n3.29\n152515\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLake\n56259\n4.34\n68024\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLassen\n59515\n5.97\n31873\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nLos Angeles\n83411\n0.53\n9936690\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMadera\n73543\n3.87\n157243\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMarin\n142019\n2.89\n260485\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMariposa\n60021\n8.82\n17130\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nMendocino\n61335\n3.58\n91145\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMerced\n64772\n3.31\n282290\nHigh Confidence\nSafe for algorithmic decisions\n\n\nModoc\n54962\n9.80\n8651\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nMono\n82038\n18.76\n13219\nLow Confidence\nRequires manual review or additional data\n\n\nMonterey\n91043\n2.09\n437609\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNapa\n105809\n2.82\n137384\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNevada\n79395\n4.82\n102322\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOrange\n109361\n0.81\n3175227\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPlacer\n109375\n1.70\n406608\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPlumas\n67885\n11.45\n19650\nLow Confidence\nRequires manual review or additional data\n\n\nRiverside\n84505\n1.26\n2429487\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSacramento\n84010\n0.97\n1579211\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Benito\n104451\n5.23\n64753\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nSan Bernardino\n77423\n1.04\n2180563\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Diego\n96974\n1.02\n3289701\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Francisco\n136689\n1.43\n851036\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Joaquin\n82837\n1.75\n779445\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Luis Obispo\n90158\n2.56\n281712\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Mateo\n149907\n1.75\n754250\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Barbara\n92332\n2.05\n445213\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Clara\n153792\n1.00\n1916831\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Cruz\n104409\n3.04\n268571\nHigh Confidence\nSafe for algorithmic decisions\n\n\nShasta\n68347\n3.63\n181852\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSierra\n61108\n15.12\n2916\nLow Confidence\nRequires manual review or additional data\n\n\nSiskiyou\n53898\n4.90\n44049\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSolano\n97037\n1.78\n450995\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSonoma\n99266\n2.00\n488436\nHigh Confidence\nSafe for algorithmic decisions\n\n\nStanislaus\n74872\n1.83\n552063\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSutter\n72654\n4.71\n99101\nHigh Confidence\nSafe for algorithmic decisions\n\n\nTehama\n59029\n6.95\n65484\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nTrinity\n47317\n12.45\n15889\nLow Confidence\nRequires manual review or additional data\n\n\nTulare\n64474\n2.31\n473446\nHigh Confidence\nSafe for algorithmic decisions\n\n\nTuolumne\n70432\n6.66\n54993\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nVentura\n102141\n1.50\n842009\nHigh Confidence\nSafe for algorithmic decisions\n\n\nYolo\n85097\n2.74\n217141\nHigh Confidence\nSafe for algorithmic decisions\n\n\nYuba\n66693\n4.19\n81705\nHigh Confidence\nSafe for algorithmic decisions\n\n\n\n\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nCounties suitable for immediate algorithmic implementation: [List counties with high confidence data and explain why they’re appropriate] Alameda Butte Calaveras Contra Costa El Dorado Fresno Humboldt Imperial Kern Kings Lake Los Angeles Madera Marin Mendocino Merced Monterey Napa Nevada Orange Placer Riverside Sacramento San Bernardino San Diego San Francisco San Joaquin San Luis Obispo San Mateo Santa Barbara Santa Clara Santa Cruz Shasta Siskiyou Solano Sonoma Stanislaus Sutter Tulare Ventura Yolo Yuba These counties have large populations and exceptionally large sample sizes, resulting in an extremely low margin of error (MOE) of approximately 1%. Their income estimates are highly stable, and the risk of algorithmic bias in these areas is minimal, making them safe for automated funding allocation.\nCounties requiring additional oversight: [List counties with moderate confidence data and describe what kind of monitoring would be needed] Amador Colusa Del Norte Glenn Inyo Lassen Mariposa Modoc San Benito Tehama Tuolumne Although the data is generally accurate, it exhibits a certain degree of volatility. It is recommended that while implementing the algorithm, an output monitoring mechanism be established to periodically conduct random sampling and inspection of anomalous allocation cases, ensuring the algorithm does not develop bias due to data fluctuations.\nCounties needing alternative approaches: [List counties with low confidence data and suggest specific alternatives - manual review, additional surveys, etc.] Alpine Mono Plumas Sierra Trinity These counties have sparse populations, resulting in extremely unstable data with errors exceeding 17%. Direct application of algorithms would lead to severe geographic inequities. A “manual verification” mechanism could be implemented for these counties, or supplementary investigations could be conducted using state government administrative records to compensate for the shortcomings of census sample data."
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#questions-for-further-investigation",
    "href": "Labs/Lab_1/lab1_template.html#questions-for-further-investigation",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "Questions for Further Investigation",
    "text": "Questions for Further Investigation\n[List 2-3 questions that your analysis raised that you’d like to explore further in future assignments. Consider questions about spatial patterns, time trends, or other demographic factors.] 1.Has the reliability of data for these remote counties improved or deteriorated over the past decade as the Census Bureau updated its sampling methods? 2.Could incorporating “income” alongside other metrics help reduce bias in the final results? # Technical Notes\nData Sources: - U.S. Census Bureau, American Community Survey 2018-2022 5-Year Estimates - Retrieved via tidycensus R package on February 9, 2026.\nReproducibility: - All analysis conducted in R version 4.3.0 - Census API key required for replication - Complete code and documentation available at: [your portfolio URL]\nMethodology Notes: County and tract names were cleaned using regular expressions to remove repetitive legal suffixes (e.g., “; California”), ensuring the final visualizations and tables were policy-ready.\nLimitations: The focus was restricted to California (CA); findings regarding rural data uncertainty may vary in states with different administrative structures or population distributions."
  },
  {
    "objectID": "Labs/Lab_1/lab1_template.html#submission-checklist",
    "href": "Labs/Lab_1/lab1_template.html#submission-checklist",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\nAll code chunks run without errors\nAll “[Fill this in]” prompts have been completed\nTables are properly formatted and readable\nExecutive summary addresses all four required components\nPortfolio navigation includes this assignment\nCensus API key is properly set\nDocument renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/labs/lab_1/your_file_name.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yiting Zhong-MUSA 5080 Portfolio",
    "section": "",
    "text": "This portfolio documents my learning journey in Public Policy Analytics (MUSA 5080).\n\n\nAdvanced spatial analysis and data science for urban planning and public policy.\n\n\n\n\nWeekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge\n\n\n\n\nI am first year MCP student.\n\n\n\n\nEmail: [yzhong06@upenn.edu]\nGitHub: [yitingzzzttt]"
  },
  {
    "objectID": "index.html#about-this-course",
    "href": "index.html#about-this-course",
    "title": "Yiting Zhong-MUSA 5080 Portfolio",
    "section": "",
    "text": "Advanced spatial analysis and data science for urban planning and public policy."
  },
  {
    "objectID": "index.html#portfolio-structure",
    "href": "index.html#portfolio-structure",
    "title": "Yiting Zhong-MUSA 5080 Portfolio",
    "section": "",
    "text": "Weekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Yiting Zhong-MUSA 5080 Portfolio",
    "section": "",
    "text": "I am first year MCP student."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Yiting Zhong-MUSA 5080 Portfolio",
    "section": "",
    "text": "Email: [yzhong06@upenn.edu]\nGitHub: [yitingzzzttt]"
  },
  {
    "objectID": "Labs/Lab_2/lab2_template.html",
    "href": "Labs/Lab_2/lab2_template.html",
    "title": "Lab 2: Spatial Analysis and Visualization",
    "section": "",
    "text": "Learning Objectives: - Apply spatial operations to answer policy-relevant research questions - Integrate census demographic data with spatial analysis - Create publication-quality visualizations and maps - Work with spatial data from multiple sources - Communicate findings effectively for policy audiences"
  },
  {
    "objectID": "Labs/Lab_2/lab2_template.html#assignment-overview",
    "href": "Labs/Lab_2/lab2_template.html#assignment-overview",
    "title": "Lab 2: Spatial Analysis and Visualization",
    "section": "",
    "text": "Learning Objectives: - Apply spatial operations to answer policy-relevant research questions - Integrate census demographic data with spatial analysis - Create publication-quality visualizations and maps - Work with spatial data from multiple sources - Communicate findings effectively for policy audiences"
  },
  {
    "objectID": "Labs/Lab_2/lab2_template.html#part-1-healthcare-access-for-vulnerable-populations",
    "href": "Labs/Lab_2/lab2_template.html#part-1-healthcare-access-for-vulnerable-populations",
    "title": "Lab 2: Spatial Analysis and Visualization",
    "section": "Part 1: Healthcare Access for Vulnerable Populations",
    "text": "Part 1: Healthcare Access for Vulnerable Populations\n\nResearch Question\nWhich Pennsylvania counties have the highest proportion of vulnerable populations (elderly + low-income) living far from hospitals?\nYour analysis should identify counties that should be priorities for healthcare investment and policy intervention.\n\n\nRequired Analysis Steps\nComplete the following analysis, documenting each step with code and brief explanations:\n\nStep 1: Data Collection (5 points)\nLoad the required spatial data: - Pennsylvania county boundaries - Pennsylvania hospitals (from lecture data) - Pennsylvania census tracts\nYour Task:\n\n# Load required packages\nlibrary(sf)         \nlibrary(tidyverse)  \nlibrary(tigris)\nsetwd(\"C:/Users/yzhon/OneDrive - PennO365/Penn-Spring 2026/CPLN 592/cpln-5920-sp26-student-portfolio-template/Labs/Lab_2/Pennsylvania_County_Boundaries\")\npa_counties&lt;- st_read(\"Pennsylvania_County_Boundaries.shp\")\n\nReading layer `Pennsylvania_County_Boundaries' from data source \n  `C:\\Users\\yzhon\\OneDrive - PennO365\\Penn-Spring 2026\\CPLN 592\\cpln-5920-sp26-student-portfolio-template\\Labs\\Lab_2\\Pennsylvania_County_Boundaries\\Pennsylvania_County_Boundaries.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 67 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -8963377 ymin: 4825316 xmax: -8314404 ymax: 5201413\nProjected CRS: WGS 84 / Pseudo-Mercator\n\npa_tracts&lt;- tracts(state = \"PA\",cb=TRUE,class=\"sf\")\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=======                                                               |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |===================                                                   |  28%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |============================                                          |  41%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |========================================================              |  81%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===============================================================       |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n\npa_hospitals&lt;-st_read(\"C:/Users/yzhon/OneDrive - PennO365/Penn-Spring 2026/CPLN 592/cpln-5920-sp26-student-portfolio-template/Labs/Lab_2/hospitals.geojson\")\n\nReading layer `hospitals' from data source \n  `C:\\Users\\yzhon\\OneDrive - PennO365\\Penn-Spring 2026\\CPLN 592\\cpln-5920-sp26-student-portfolio-template\\Labs\\Lab_2\\hospitals.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 223 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -80.49621 ymin: 39.75163 xmax: -74.86704 ymax: 42.13403\nGeodetic CRS:  WGS 84\n\n\nQuestions to answer: - How many hospitals are in your dataset? 223 - How many census tracts? 3445 - What coordinate reference system is each dataset in? pa_hospitals=WGS 84 ,“EPSG”,4326 pa_tracts=NAD83,“EPSG”,4269 pa_counties=WGS 84,“EPSG”,3857 —\n\n\nStep 2: Get Demographic Data\nUse tidycensus to download tract-level demographic data for Pennsylvania.\nRequired variables: - Total population - Median household income - Population 65 years and over (you may need to sum multiple age categories)\nYour Task:\n\n# Get demographic data from ACS\nlibrary(tidycensus)\nvars &lt;- c(\n  total_pop = \"B01001_001\",     \n  med_income = \"B19013_001\",    \n  m65_66 = \"B01001_020\", m67_69 = \"B01001_021\", m70_74 = \"B01001_022\", \n  m75_79 = \"B01001_023\", m80_84 = \"B01001_024\", m85_plus = \"B01001_025\",\n  f65_66 = \"B01001_044\", f67_69 = \"B01001_045\", f70_74 = \"B01001_046\", \n  f75_79 = \"B01001_047\", f80_84 = \"B01001_048\", f85_plus = \"B01001_049\"\n)\npa_census_data &lt;- get_acs(\n  geography = \"tract\",\n  variables = vars,\n  state = \"PA\",\n  year = 2022, \n  output = \"wide\" \n)\npa_demographics &lt;- pa_census_data %&gt;%\n  mutate(\n    elderly_pop = rowSums(select(., m65_66E:f85_plusE)),\n    elderly_pct = (elderly_pop / total_popE) * 100\n  ) %&gt;%\n  rename(\n    total_population = total_popE,\n    median_income = med_incomeE\n  ) %&gt;%\n  select(GEOID, NAME, total_population, median_income, elderly_pop, elderly_pct)\n\n# Join to tract boundaries\npa_tracts_with_data &lt;- pa_tracts %&gt;%\n  left_join(pa_demographics, by = \"GEOID\")\n\nQuestions to answer: - What year of ACS data are you using? 2022 - How many tracts have missing income data? 62 - What is the median income across all PA census tracts? 70188 —\n\n\nStep 3: Define Vulnerable Populations\nIdentify census tracts with vulnerable populations based on TWO criteria: 1. Low median household income (choose an appropriate threshold) 2. Significant elderly population (choose an appropriate threshold)\nYour Task:\n\n# Filter for vulnerable tracts based on your criteria\npa_valid_data &lt;- pa_tracts_with_data %&gt;%\n  filter(!is.na(median_income)) %&gt;%\n  filter(total_population &gt; 0)\n\nincome_limit &lt;- 55924\nelderly_limit&lt;- 37.7\n\n\npa_vulnerable_populations &lt;- pa_valid_data %&gt;%\n  mutate(\n    is_vulnerable = ifelse(\n      !is.na(median_income) & \n      median_income &lt;= income_limit & \n      elderly_pct &gt;= elderly_limit, \n      TRUE, \n      FALSE\n    )\n  ) %&gt;%\n  filter(is_vulnerable == TRUE)\n\nQuestions to answer: - What income threshold did you choose and why? 55924, I use the 75% quantile. quantile(pa_valid_data$elderly_pct,0.25, na.rm = TRUE)\n\nWhat elderly population threshold did you choose and why? 37.7, I found that the 75th percentile is approximately 25%. This means this threshold helps me identify the top 25% of communities with the highest aging levels across the state. quantile(pa_valid_data$elderly_pct,0.75, na.rm = TRUE)\nHow many tracts meet your vulnerability criteria? 209\nWhat percentage of PA census tracts are considered vulnerable by your definition? 209/3445=6.07% —\n\n\n\nStep 4: Calculate Distance to Hospitals\nFor each vulnerable tract, calculate the distance to the nearest hospital.\nYour Task:\n\npa_vulnerable_projected &lt;- st_transform(pa_vulnerable_populations, 2272)\npa_hospitals_projected &lt;- st_transform(pa_hospitals, 2272)\n\nvulnerable_centroids &lt;- st_centroid(pa_vulnerable_projected)\n\ndistance&lt;- st_distance(vulnerable_centroids,pa_hospitals_projected)\n\npa_vulnerable_projected$dist_to_hospital_miles &lt;- as.numeric(apply(distance, 1, min)) / 5280\n\nRequirements: - Use an appropriate projected coordinate system for Pennsylvania - Calculate distances in miles - Explain why you chose your projection I use South Philadelphia projection CRS.\nQuestions to answer: - What is the average distance to the nearest hospital for vulnerable tracts? 3.538635\n\nWhat is the maximum distance? 19.15822\nHow many vulnerable tracts are more than 15 miles from the nearest hospital? 7 —\n\n\n\nStep 5: Identify Underserved Areas\nDefine “underserved” as vulnerable tracts that are more than 15 miles from the nearest hospital.\nYour Task:\n\npa_vulnerable_projected&lt;- pa_vulnerable_projected %&gt;%\n  mutate(is_underserved = dist_to_hospital_miles &gt; 15)\n\nQuestions to answer: - How many tracts are underserved? 7\n\nWhat percentage of vulnerable tracts are underserved? 7/209=3.34%\nDoes this surprise you? Why or why not? Yes, because there are almost 20,000 of population have to go to hospital that is more than 15 miles away. —\n\n\n\nStep 6: Aggregate to County Level\nUse spatial joins and aggregation to calculate county-level statistics about vulnerable populations and hospital access.\nYour Task:\n\n# Spatial join tracts to counties\npa_counties_projected &lt;- st_transform(pa_counties, 2272)\nvulnerable_with_county &lt;- st_join(pa_vulnerable_projected, pa_counties_projected)\n\n# Aggregate statistics by county\ncounty_summary &lt;- vulnerable_with_county %&gt;%\n  group_by(NAMELSADCO) %&gt;%\n  summarize(\n    num_vulnerable_tracts=n(),\n    num_underserved_tracts = sum(is_underserved),\n    avg_distance=mean(dist_to_hospital_miles),\n    total_vulnerable_population=sum(total_population,na.rm = TRUE))%&gt;%\n      mutate(\n        pct_vul_tracts_underserved=((num_underserved_tracts / num_vulnerable_tracts)*100)\n      )\n\nRequired county-level statistics: - Number of vulnerable tracts - Number of underserved tracts\n- Percentage of vulnerable tracts that are underserved - Average distance to nearest hospital for vulnerable tracts - Total vulnerable population\nQuestions to answer: - Which 5 counties have the highest percentage of underserved vulnerable tracts? Forest County, Juniata County, Monroe County, Sullivan County,Dauphin County\n\nWhich counties have the most vulnerable people living far from hospitals? Forest County\nAre there any patterns in where underserved counties are located? Underserved counties are primarily concentrated in the rural, mountainous central and northern regions of PA, where low population density leads to sparse hospital coverage. —\n\n\n\nStep 7: Create Summary Table\nCreate a professional table showing the top 10 priority counties for healthcare investment.\nYour Task:\n\nlibrary(knitr)\n# Create and format priority counties table\ntop_10_counties&lt;-county_summary%&gt;%\n  st_drop_geometry()%&gt;%\n  arrange(desc(pct_vul_tracts_underserved))%&gt;%\n  head(10)%&gt;%\n  mutate(\n    avg_distance = round(avg_distance, 1)\n  )\n  \n\ntop_10_counties %&gt;%\n  kable(\n    col.names = c(\"County Name\", \"Vulnerable Tracts\", \"Underserved Tracts\", \n                  \"Avg. Distance (mi)\", \"Total Vulnerable Pop\", \"% Underserved\"),\n    caption = \"Top 10 Pennsylvania Counties Prioritized for Healthcare Investment\",\n    align = \"lccccc\"\n  )\n\n\nTop 10 Pennsylvania Counties Prioritized for Healthcare Investment\n\n\n\n\n\n\n\n\n\n\nCounty Name\nVulnerable Tracts\nUnderserved Tracts\nAvg. Distance (mi)\nTotal Vulnerable Pop\n% Underserved\n\n\n\n\nForest County\n4\n4\n18.1\n10804\n100\n\n\nJuniata County\n5\n5\n15.9\n8910\n100\n\n\nMonroe County\n1\n1\n17.7\n1299\n100\n\n\nSullivan County\n4\n4\n16.9\n3672\n100\n\n\nDauphin County\n4\n3\n14.6\n16446\n75\n\n\nBradford County\n2\n1\n9.3\n8736\n50\n\n\nClearfield County\n4\n2\n9.0\n17256\n50\n\n\nAllegheny County\n35\n0\n2.3\n78986\n0\n\n\nArmstrong County\n1\n0\n3.1\n2850\n0\n\n\nBeaver County\n7\n0\n3.1\n13889\n0\n\n\n\n\n\nRequirements: - Use knitr::kable() or similar for formatting - Include descriptive column names - Format numbers appropriately (commas for population, percentages, etc.) - Add an informative caption - Sort by priority (you decide the metric)"
  },
  {
    "objectID": "Labs/Lab_2/lab2_template.html#part-2-comprehensive-visualization",
    "href": "Labs/Lab_2/lab2_template.html#part-2-comprehensive-visualization",
    "title": "Lab 2: Spatial Analysis and Visualization",
    "section": "Part 2: Comprehensive Visualization",
    "text": "Part 2: Comprehensive Visualization\nUsing the skills from Week 3 (Data Visualization), create publication-quality maps and charts.\n\nMap 1: County-Level Choropleth\nCreate a choropleth map showing healthcare access challenges at the county level.\nYour Task:\n\n# Create county-level access map\n\nRequirements: - Fill counties by percentage of vulnerable tracts that are underserved - Include hospital locations as points - Use an appropriate color scheme - Include clear title, subtitle, and caption - Use theme_void() or similar clean theme - Add a legend with formatted labels\n\n\n\nMap 2: Detailed Vulnerability Map\nCreate a map highlighting underserved vulnerable tracts.\nYour Task:\n\n# Create detailed tract-level map\n\nRequirements: - Show underserved vulnerable tracts in a contrasting color - Include county boundaries for context - Show hospital locations - Use appropriate visual hierarchy (what should stand out?) - Include informative title and subtitle\n\n\n\nChart: Distribution Analysis\nCreate a visualization showing the distribution of distances to hospitals for vulnerable populations.\nYour Task:\n\n# Create distribution visualization\n\nSuggested chart types: - Histogram or density plot of distances - Box plot comparing distances across regions - Bar chart of underserved tracts by county - Scatter plot of distance vs. vulnerable population size\nRequirements: - Clear axes labels with units - Appropriate title - Professional formatting - Brief interpretation (1-2 sentences as a caption or in text)"
  },
  {
    "objectID": "Labs/Lab_2/lab2_template.html#part-3-bring-your-own-data-analysis",
    "href": "Labs/Lab_2/lab2_template.html#part-3-bring-your-own-data-analysis",
    "title": "Lab 2: Spatial Analysis and Visualization",
    "section": "Part 3: Bring Your Own Data Analysis",
    "text": "Part 3: Bring Your Own Data Analysis\nChoose your own additional spatial dataset and conduct a supplementary analysis.\n\nChallenge Options\nChoose ONE of the following challenge exercises, or propose your own research question using OpenDataPhilly data (https://opendataphilly.org/datasets/).\nNote these are just loose suggestions to spark ideas - follow or make your own as the data permits and as your ideas evolve. This analysis should include bringing in your own dataset, ensuring the projection/CRS of your layers align and are appropriate for the analysis (not lat/long or geodetic coordinate systems). The analysis portion should include some combination of spatial and attribute operations to answer a relatively straightforward question\n\n\nEducation & Youth Services\nOption A: Educational Desert Analysis - Data: Schools, Libraries, Recreation Centers, Census tracts (child population) - Question: “Which neighborhoods lack adequate educational infrastructure for children?” - Operations: Buffer schools/libraries (0.5 mile walking distance), identify coverage gaps, overlay with child population density - Policy relevance: School district planning, library placement, after-school program siting\nOption B: School Safety Zones - Data: Schools, Crime Incidents, Bike Network - Question: “Are school zones safe for walking/biking, or are they crime hotspots?” - Operations: Buffer schools (1000ft safety zone), spatial join with crime incidents, assess bike infrastructure coverage - Policy relevance: Safe Routes to School programs, crossing guard placement\n\n\n\nEnvironmental Justice\nOption C: Green Space Equity - Data: Parks, Street Trees, Census tracts (race/income demographics) - Question: “Do low-income and minority neighborhoods have equitable access to green space?” - Operations: Buffer parks (10-minute walk = 0.5 mile), calculate tree canopy or park acreage per capita, compare by demographics - Policy relevance: Climate resilience, environmental justice, urban forestry investment —\n\n\nPublic Safety & Justice\nOption D: Crime & Community Resources - Data: Crime Incidents, Recreation Centers, Libraries, Street Lights - Question: “Are high-crime areas underserved by community resources?” - Operations: Aggregate crime counts to census tracts or neighborhoods, count community resources per area, spatial correlation analysis - Policy relevance: Community investment, violence prevention strategies —\n\n\nInfrastructure & Services\nOption E: Polling Place Accessibility - Data: Polling Places, SEPTA stops, Census tracts (elderly population, disability rates) - Question: “Are polling places accessible for elderly and disabled voters?” - Operations: Buffer polling places and transit stops, identify vulnerable populations, find areas lacking access - Policy relevance: Voting rights, election infrastructure, ADA compliance\n\n\n\nHealth & Wellness\nOption F: Recreation & Population Health - Data: Recreation Centers, Playgrounds, Parks, Census tracts (demographics) - Question: “Is lack of recreation access associated with vulnerable populations?” - Operations: Calculate recreation facilities per capita by neighborhood, buffer facilities for walking access, overlay with demographic indicators - Policy relevance: Public health investment, recreation programming, obesity prevention\n\n\n\nEmergency Services\nOption G: EMS Response Coverage - Data: Fire Stations, EMS stations, Population density, High-rise buildings - Question: “Are population-dense areas adequately covered by emergency services?” - Operations: Create service area buffers (5-minute drive = ~2 miles), assess population coverage, identify gaps in high-density areas - Policy relevance: Emergency preparedness, station siting decisions\n\n\n\nArts & Culture\nOption H: Cultural Asset Distribution - Data: Public Art, Museums, Historic sites/markers, Neighborhoods - Question: “Do all neighborhoods have equitable access to cultural amenities?” - Operations: Count cultural assets per neighborhood, normalize by population, compare distribution across demographic groups - Policy relevance: Cultural equity, tourism, quality of life, neighborhood identity\n\n\n\n\nData Sources\nOpenDataPhilly: https://opendataphilly.org/datasets/ - Most datasets available as GeoJSON, Shapefile, or CSV with coordinates - Always check the Metadata for a data dictionary of the fields.\nAdditional Sources: - Pennsylvania Open Data: https://data.pa.gov/ - Census Bureau (via tidycensus): Demographics, economic indicators, commute patterns - TIGER/Line (via tigris): Geographic boundaries\n\n\nRecommended Starting Points\nIf you’re feeling confident: Choose an advanced challenge with multiple data layers. If you are a beginner, choose something more manageable that helps you understand the basics\nIf you have a different idea: Propose your own question! Just make sure: - You can access the spatial data - You can perform at least 2 spatial operations\n\n\nYour Analysis\nYour Task:\n\nFind and load additional data\n\nDocument your data source\nCheck and standardize the CRS\nProvide basic summary statistics\n\n\n\n# Load your additional dataset\n\nQuestions to answer: - What dataset did you choose and why? - What is the data source and date? - How many features does it contain? - What CRS is it in? Did you need to transform it?\n\n\nPose a research question\n\nWrite a clear research statement that your analysis will answer.\nExamples: - “Do vulnerable tracts have adequate public transit access to hospitals?” - “Are EMS stations appropriately located near vulnerable populations?” - “Do areas with low vehicle access have worse hospital access?”\n\n\nConduct spatial analysis\n\nUse at least TWO spatial operations to answer your research question.\nRequired operations (choose 2+): - Buffers - Spatial joins - Spatial filtering with predicates - Distance calculations - Intersections or unions - Point-in-polygon aggregation\nYour Task:\n\n# Your spatial analysis\n\nAnalysis requirements: - Clear code comments explaining each step - Appropriate CRS transformations - Summary statistics or counts - At least one map showing your findings - Brief interpretation of results (3-5 sentences)\nYour interpretation:\n[Write your findings here]"
  },
  {
    "objectID": "Labs/Lab_2/lab2_template.html#finally---a-few-comments-about-your-incorporation-of-feedback",
    "href": "Labs/Lab_2/lab2_template.html#finally---a-few-comments-about-your-incorporation-of-feedback",
    "title": "Lab 2: Spatial Analysis and Visualization",
    "section": "Finally - A few comments about your incorporation of feedback!",
    "text": "Finally - A few comments about your incorporation of feedback!\nTake a few moments to clean up your markdown document and then write a line or two or three about how you may have incorporated feedback that you recieved after your first assignment."
  },
  {
    "objectID": "Labs/Lab_2/lab2_template.html#submission-requirements",
    "href": "Labs/Lab_2/lab2_template.html#submission-requirements",
    "title": "Lab 2: Spatial Analysis and Visualization",
    "section": "Submission Requirements",
    "text": "Submission Requirements\nWhat to submit:\n\nRendered HTML document posted to your course portfolio with all code, outputs, maps, and text\n\nUse embed-resources: true in YAML so it’s a single file\nAll code should run without errors\nAll maps and charts should display correctly\n\nSubmit the correct and working links of your assignment on Canvas"
  }
]